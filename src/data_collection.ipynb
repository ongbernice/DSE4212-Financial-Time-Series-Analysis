{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "We collected historical data of 8 stocks from Yahoo Finance using the `yfinance` library from 1 September 2017 to 1 October 2024.\n",
    "- AAPL\n",
    "- MSFT\n",
    "- GOOGL\n",
    "- AMZN\n",
    "- TSLA\n",
    "- META\n",
    "- ^GSPC: S&P 500 Index (market index)\n",
    "- ^TNX: U.S. 10-Year Treasury yield (interest rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download stock data from Yahoo Finance.\n",
    "    \n",
    "    :param ticker: Stock ticker symbol (e.g., AAPL for Apple).\n",
    "    :param start_date: Start date for the data (YYYY-MM-DD).\n",
    "    :param end_date: End date for the data (YYYY-MM-DD).\n",
    "    :return: DataFrame with stock data.\n",
    "    \"\"\"\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for AAPL saved to data/aapl.csv\n",
      "Raw data for MSFT saved to data/msft.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for GOOGL saved to data/googl.csv\n",
      "Raw data for AMZN saved to data/amzn.csv\n",
      "Raw data for TSLA saved to data/tsla.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for META saved to data/meta.csv\n",
      "Raw data for ^GSPC saved to data/^gspc.csv\n",
      "Raw data for ^TNX saved to data/^tnx.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect raw data\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # List of stock tickers to process\n",
    "    stock_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', '^GSPC', '^TNX']\n",
    "    \n",
    "    # Start and end dates for data collection\n",
    "    start_date = '2017-09-01'\n",
    "    end_date = '2024-10-01'\n",
    "    \n",
    "    for ticker in stock_tickers:\n",
    "        # Download stock data\n",
    "        data = download_stock_data(ticker, start_date, end_date)\n",
    "        \n",
    "        # Save the preprocessed data to a CSV file\n",
    "        data.to_csv(f\"../data/{ticker.lower()}.csv\")\n",
    "        \n",
    "        print(f\"Raw data for {ticker} saved to data/{ticker.lower()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "We combine the Adjusted Close Price from each stock into a single dataframe and perform feature engineering by calculating technical indicators like Simple Moving Average (SMA) and Exponential Moving Average (EMA) of **AAPL** Stock Price. Missing values are also dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock \u001b[38;5;129;01min\u001b[39;00m stocks:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstock\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     dfs[stock] \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \u001b[38;5;66;03m# Focus on 'Adj Close' prices\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Concatenate the data into a single dataframe, aligning by date\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:162\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_parse_dates_presence(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:215\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m col_indices \u001b[38;5;241m=\u001b[39m [names_dict[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames]  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m noconvert_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_noconvert_dtype_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m noconvert_columns:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mset_noconvert(col)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:663\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[0;34m(self, col_indices, names)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col:\n\u001b[0;32m--> 663\u001b[0m         noconvert_columns\u001b[38;5;241m.\u001b[39madd(\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     noconvert_columns\u001b[38;5;241m.\u001b[39madd(_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:640\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    637\u001b[0m     x \u001b[38;5;241m=\u001b[39m usecols[x]\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(x):\n\u001b[0;32m--> 640\u001b[0m     x \u001b[38;5;241m=\u001b[39m col_indices[\u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "stocks = ['aapl', 'msft', 'googl', 'amzn', 'tsla', 'meta', '^gspc', '^tnx']\n",
    "dfs = {}\n",
    "\n",
    "for stock in stocks:\n",
    "    df = pd.read_csv(f'../data/{stock}.csv', index_col='Date', parse_dates=True)\n",
    "    dfs[stock] = df[['Adj Close']]  # Focus on 'Adj Close' prices\n",
    "\n",
    "# Concatenate the data into a single dataframe, aligning by date\n",
    "data = pd.concat([dfs[stock] for stock in stocks], axis=1)\n",
    "data.columns = [stock + '_adj_close' for stock in stocks]\n",
    "data = data.rename(columns={'^gspc_adj_close': 'sp500_adj_close'})  # Rename S&P 500 column\n",
    "data = data.rename(columns={'^tnx_adj_close': '10y_treasury_yield'})  # Rename 10-year Treasury yield column\n",
    "\n",
    "# Feature engineering\n",
    "data['aapl_sma_10'] = data['aapl_adj_close'].rolling(window=10).mean()\n",
    "data['aapl_ema_20'] = data['aapl_adj_close'].ewm(span=20, adjust=False).mean()  # 20-day EMA\n",
    "\n",
    "data = data.dropna()  # Drop rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our Y (target to predict) and X (features) series:\n",
    "\n",
    "Y: **AAPL** Daily Adjusted Close Price\n",
    "\n",
    "X: \n",
    "- 1-Day Lags of MSFT, GOOGL, AMZN, TSLA, META, SP500 Adjusted Close Price\n",
    "- 1-Day Lag of U.S. 10-Year Treasury yield\n",
    "- 1-Day Lags of technical indicators: SMA, EMA of AAPL's Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl_adj_close</th>\n",
       "      <th>msft_adj_close_lag</th>\n",
       "      <th>googl_adj_close_lag</th>\n",
       "      <th>amzn_adj_close_lag</th>\n",
       "      <th>tsla_adj_close_lag</th>\n",
       "      <th>meta_adj_close_lag</th>\n",
       "      <th>sp500_adj_close_lag</th>\n",
       "      <th>10y_treasury_yield_lag</th>\n",
       "      <th>aapl_sma_10_lag</th>\n",
       "      <th>aapl_ema_20_lag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>37.234501</td>\n",
       "      <td>69.565742</td>\n",
       "      <td>46.648991</td>\n",
       "      <td>49.339500</td>\n",
       "      <td>25.320667</td>\n",
       "      <td>171.124756</td>\n",
       "      <td>2500.229980</td>\n",
       "      <td>2.202</td>\n",
       "      <td>37.736682</td>\n",
       "      <td>37.964495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-19</th>\n",
       "      <td>37.248585</td>\n",
       "      <td>69.427216</td>\n",
       "      <td>46.372673</td>\n",
       "      <td>48.709499</td>\n",
       "      <td>25.666668</td>\n",
       "      <td>169.499649</td>\n",
       "      <td>2503.870117</td>\n",
       "      <td>2.229</td>\n",
       "      <td>37.610431</td>\n",
       "      <td>37.894972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-20</th>\n",
       "      <td>36.624371</td>\n",
       "      <td>69.685829</td>\n",
       "      <td>46.727295</td>\n",
       "      <td>48.493000</td>\n",
       "      <td>25.006666</td>\n",
       "      <td>172.002121</td>\n",
       "      <td>2506.649902</td>\n",
       "      <td>2.243</td>\n",
       "      <td>37.531819</td>\n",
       "      <td>37.833411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21</th>\n",
       "      <td>35.995461</td>\n",
       "      <td>69.223961</td>\n",
       "      <td>47.259975</td>\n",
       "      <td>48.660500</td>\n",
       "      <td>24.927334</td>\n",
       "      <td>171.653168</td>\n",
       "      <td>2508.239990</td>\n",
       "      <td>2.277</td>\n",
       "      <td>37.394775</td>\n",
       "      <td>37.718264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22</th>\n",
       "      <td>35.643456</td>\n",
       "      <td>68.549644</td>\n",
       "      <td>47.260471</td>\n",
       "      <td>48.232498</td>\n",
       "      <td>24.431999</td>\n",
       "      <td>170.596359</td>\n",
       "      <td>2500.600098</td>\n",
       "      <td>2.278</td>\n",
       "      <td>37.210093</td>\n",
       "      <td>37.554188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            aapl_adj_close  msft_adj_close_lag  googl_adj_close_lag  \\\n",
       "Date                                                                  \n",
       "2017-09-18       37.234501           69.565742            46.648991   \n",
       "2017-09-19       37.248585           69.427216            46.372673   \n",
       "2017-09-20       36.624371           69.685829            46.727295   \n",
       "2017-09-21       35.995461           69.223961            47.259975   \n",
       "2017-09-22       35.643456           68.549644            47.260471   \n",
       "\n",
       "            amzn_adj_close_lag  tsla_adj_close_lag  meta_adj_close_lag  \\\n",
       "Date                                                                     \n",
       "2017-09-18           49.339500           25.320667          171.124756   \n",
       "2017-09-19           48.709499           25.666668          169.499649   \n",
       "2017-09-20           48.493000           25.006666          172.002121   \n",
       "2017-09-21           48.660500           24.927334          171.653168   \n",
       "2017-09-22           48.232498           24.431999          170.596359   \n",
       "\n",
       "            sp500_adj_close_lag  10y_treasury_yield_lag  aapl_sma_10_lag  \\\n",
       "Date                                                                       \n",
       "2017-09-18          2500.229980                   2.202        37.736682   \n",
       "2017-09-19          2503.870117                   2.229        37.610431   \n",
       "2017-09-20          2506.649902                   2.243        37.531819   \n",
       "2017-09-21          2508.239990                   2.277        37.394775   \n",
       "2017-09-22          2500.600098                   2.278        37.210093   \n",
       "\n",
       "            aapl_ema_20_lag  \n",
       "Date                         \n",
       "2017-09-18        37.964495  \n",
       "2017-09-19        37.894972  \n",
       "2017-09-20        37.833411  \n",
       "2017-09-21        37.718264  \n",
       "2017-09-22        37.554188  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['aapl_adj_close'][1:]\n",
    "X = data.drop(columns=['aapl_adj_close']).shift(1).dropna()\n",
    "X.columns = [f'{col}_lag' for col in X.columns]\n",
    "\n",
    "data = pd.concat([y, X], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data to a CSV file\n",
    "data.to_csv(\"../data/stocks_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
